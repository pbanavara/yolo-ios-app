//
//  VNOnnxHandler.swift
//  YOLO
//
//  Created by Pradeep Banavara on 25/03/24.
//  Copyright Â© 2024 Ultralytics. All rights reserved.
//

import Foundation
import Vision
import CoreGraphics
import VideoToolbox
import UIKit

class VNOnnxHandler {
    var sampleBuffer: CVImageBuffer?
    var ortSession: ORTSession
    init(cvImageBufffer: CVImageBuffer, session: ORTSession) {
        sampleBuffer = cvImageBufffer
        ortSession = session
        
    }
    
    private func convertImageBufferToData(sampleBuffer: CVPixelBuffer) -> NSData {
        let imageBuffer = sampleBuffer
        CVPixelBufferLockBaseAddress(imageBuffer, CVPixelBufferLockFlags(rawValue: 0))
        let bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer)
        let height = CVPixelBufferGetHeight(imageBuffer)
        let src_buff = CVPixelBufferGetBaseAddress(imageBuffer)
        let data = NSData(bytes: src_buff, length: bytesPerRow * height)
        CVPixelBufferUnlockBaseAddress(imageBuffer, CVPixelBufferLockFlags(rawValue: 0))
        return data
    }
    
    func perform(_ requests: [VNOnnxRequest]) throws -> ORTValue {
        var result: ORTValue?
        for request in requests {
            
            let uiImage = UIImage(cgImage: CGImage.create(from: sampleBuffer!)!)
            
            let inputData = uiImage.pngData()
            let inputDataLength = inputData?.count
            let inputShape = [NSNumber(integerLiteral: inputDataLength!)]
            
            let inputTensor = try ORTValue(tensorData: NSMutableData(data: inputData!), elementType:ORTTensorElementDataType.uInt8, shape:inputShape)
            
            let inputNames = try ortSession.inputNames()    // The input names should match the model input names. Visualize the model in Netron
            let outputNames = try ortSession.outputNames()  // Check the model outnames in Netron
            
            let outputs = try ortSession.run(
                withInputs: [inputNames[0]: inputTensor], outputNames: Set(outputNames), runOptions: nil)
            guard let outputTensor = outputs[outputNames[0]] else {
                fatalError("Failed to get model keypoint output from inference.")
            }
            result = outputTensor
        }
        return result!
    }
    
    func performImage(poseUtil: OnnxPoseUtils) throws -> UIImage{
        var result: UIImage?
        
            
            let uiImage = UIImage(cgImage: CGImage.create(from: sampleBuffer!)!)
            /*
            let inputData = uiImage.pngData()
            let inputDataLength = inputData?.count
            let inputShape = [NSNumber(integerLiteral: inputDataLength!)]
            
            let inputTensor = try ORTValue(tensorData: NSMutableData(data: inputData!), elementType:ORTTensorElementDataType.uInt8, shape:inputShape)
            
            let inputNames = try ortSession.inputNames()    // The input names should match the model input names. Visualize the model in Netron
            let outputNames = try ortSession.outputNames()  // Check the model outnames in Netron
            
            let outputs = try ortSession.run(
                withInputs: [inputNames[0]: inputTensor], outputNames: Set(outputNames), runOptions: nil)
            guard let outputTensor = outputs[outputNames[0]] else {
                fatalError("Failed to get model keypoint output from inference.")
            }
             */
            result = poseUtil.plotPose(image: uiImage)
        return result!
    }
}

extension CGImage {
  static func create(from cvPixelBuffer: CVPixelBuffer?) -> CGImage? {
    guard let pixelBuffer = cvPixelBuffer else {
      return nil
    }

    var image: CGImage?
    VTCreateCGImageFromCVPixelBuffer(
      pixelBuffer,
      options: nil,
      imageOut: &image)
    return image
  }
}

